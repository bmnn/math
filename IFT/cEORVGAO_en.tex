% [p. 10]
The conditional entropy of a random variable $\operatorname{X}$ given another random variable $\operatorname{Y}$ is
$$\operatorname{H}(\operatorname{X} | \operatorname{Y}) = \sum\limits_{b \in \operatorname{supp}(\operatorname{P}_{\operatorname{Y}})} \operatorname{P}_{\operatorname{Y}}(b) \operatorname{H}(\operatorname{X} | \operatorname{Y} = b)$$
An equivalent formulation is
$$\operatorname{H}(\operatorname{X} | \operatorname{Y}) = \operatorname{E}(- \log_{2} \operatorname{P}_{\operatorname{X} | \operatorname{Y}}(\operatorname{X} | \operatorname{Y})) = \sum\limits_{(a,b) \in \operatorname{supp}(\operatorname{P}_{\operatorname{X}\operatorname{Y}})} -\operatorname{P}_{\operatorname{X}\operatorname{Y}}(a, b) \log_{2} \operatorname{P}_{\operatorname{X} | \operatorname{Y}}(a | b)$$
