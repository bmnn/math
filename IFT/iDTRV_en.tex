The informational divergence between two distributions $\operatorname{P}_{\operatorname{X}}(.)$ and $\operatorname{P}_{\operatorname{Y}}(.)$  is
$$\operatorname{D}(\operatorname{P}_{\operatorname{X}} || \operatorname{P}_{\operatorname{Y}}) = \sum\limits_{a \in \operatorname{supp}(\operatorname{P}_{\operatorname{X}})} \operatorname{P}_{\operatorname{X}}(a) \log_{2} \frac{\operatorname{P}_{\operatorname{X}}(a)}{\operatorname{P}_{\operatorname{Y}}(a)} = \operatorname{E}(\log_{2} \frac{\operatorname{P}_{\operatorname{X}}(a)}{\operatorname{P}_{\operatorname{Y}}(a)})$$
